{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY is None or AZURE_SEARCH_ENDPOINT is None or AZURE_SEARCH_KEY is None:\n",
    "    raise ValueError(\"One or more environment variables are not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings \n",
    "from langchain.vectorstores.azuresearch import AzureSearch \n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient \n",
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents.indexes.models import(\n",
    "ComplexField, CorsOptions,\n",
    "SearchIndex,\n",
    "ScoringProfile,\n",
    "SearchFieldDataType,\n",
    "SimpleField,\n",
    "SearchField,\n",
    "SearchableField,\n",
    "VectorSearch,\n",
    "HnswVectorSearchAlgorithmConfiguration\n",
    ")\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search= VectorSearch(\n",
    "algorithm_configurations=[\n",
    "    HnswVectorSearchAlgorithmConfiguration(\n",
    "    name=\"my-vector-config\",\n",
    "    kind=\"hnsw\",\n",
    "    parameters={\n",
    "    \"m\": 4,\n",
    "    \"efConstruction\": 400,\n",
    "    \"efSearch\": 500, \n",
    "    \"metric\": \"cosine\"})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index client\n",
    "client = SearchIndexClient(AZURE_SEARCH_ENDPOINT, AzureKeyCredential(AZURE_SEARCH_KEY))\n",
    "# Create the index\n",
    "index_name = \"notesslides\"\n",
    "fields = [\n",
    "SimpleField(name=\"documentId\", type=SearchFieldDataType.String, filterable=True, sortable=True, key=True), \n",
    "SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "SearchField(name=\"embedding\", type=SearchFieldDataType.Collection (SearchFieldDataType.Single), searchable=True, vector_search_dimensions = 1536, vector_search_configuration =\"my-vector-config\")\n",
    "]\n",
    "index= SearchIndex(\n",
    "name=index_name,\n",
    "fields=fields,\n",
    "vector_search=vector_search\n",
    ")\n",
    "result = client.create_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "    input = text , engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into how to split our documents\n",
    "\n",
    "path = \"path to stored data.txt\"\n",
    "\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "# text_splitter = CharacterTextSplitter (chunk_size=1000, chunk_overlap=50) \n",
    "# documents = text_splitter.split_documents (documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct json\n",
    "docs = []\n",
    "for doc in documents:\n",
    "    docs.append({\"documentId\":str(uuid.uuid4()),\"content\":doc.page_content,\"embedding\":generate_embeddings(doc.page_content)})\n",
    "    json_data = json.dumps (docs)\n",
    "with open(\"HandbookContent.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload docs to index\n",
    "with open('HandbookContent.json', 'r') as f:\n",
    "    documents = json.load(f)\n",
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=index_name, credential=AzureKeyCredential(AZURE_SEARCH_KEY))\n",
    "result = search_client.upload_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "query = \"What information does this handbook has?\"\n",
    "vector = Vector (value=generate_embeddings(query), k=2, fields=\"embedding\") # top 2 results\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vectors=[vector],\n",
    "    select=[\"content\"]\n",
    "    )\n",
    "\n",
    "input_text = \" \"\n",
    "for result in results:\n",
    "    input_text += result['content'] + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling OpenAI endpoint\n",
    "openai.Completion.create(\n",
    "model=\"gpt-3.5-turbo-instruct\",\n",
    "prompt= f\" Answer the question based on given input text. Input: {input_text}. Question: {query}\",\n",
    "max_tokens=100,\n",
    "temperature=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
